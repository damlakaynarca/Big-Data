{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1a4SxWYj9tm7IDY0m8j/r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/damlakaynarca/Big-Data/blob/main/Spark_En_%C4%B0yi_Sonu%C3%A7_Tweet_Eval_Veri_Seti_%C3%9Czerinde_%C3%87al%C4%B1%C5%9Fma_Big_Data_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3h48DXl8swB",
        "outputId": "92b07e6b-7a3b-4fba-95e1-5e67b64203d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Doğruluğu: 0.99\n",
            "+--------------------+-----+----------+\n",
            "|               tweet|label|prediction|\n",
            "+--------------------+-----+----------+\n",
            "|worry is a down p...|    2|       2.0|\n",
            "|my roommate its o...|    0|       0.0|\n",
            "|no but thats so c...|    1|       1.0|\n",
            "|rooneys fucking u...|    0|       0.0|\n",
            "|its pretty depres...|    3|       3.0|\n",
            "+--------------------+-----+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+--------------------+------------+\n",
            "|               tweet|tweet_length|\n",
            "+--------------------+------------+\n",
            "|worry is a down p...|          17|\n",
            "|my roommate its o...|          14|\n",
            "|no but thats so c...|          18|\n",
            "|rooneys fucking u...|          13|\n",
            "|its pretty depres...|          11|\n",
            "|user but your pus...|          24|\n",
            "|making that yearl...|          16|\n",
            "|tiller and breezy...|          14|\n",
            "|user broadband is...|          10|\n",
            "|user look at thos...|           6|\n",
            "+--------------------+------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Gerekli Kütüphaneleri Yükleme\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz  # Spark 3.2.0 kullanacağız\n",
        "!tar -xvf spark-3.2.0-bin-hadoop3.2.tgz > /dev/null  # Dosyayı açıyoruz\n",
        "!pip install -q findspark datasets\n",
        "\n",
        "# JAVA ve SPARK ortamını ayarlama\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.0-bin-hadoop3.2\"  # Spark 3.2.0 konumunu kullanıyoruz\n",
        "\n",
        "# Spark ve Findspark'ı Başlat\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, lower, regexp_replace, udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StandardScaler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Spark Oturumu Başlat\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"TweetEval Sentiment Analysis\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Hugging Face'ten Dataset Yükleme\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# 'tweet_eval' veri setini indirme\n",
        "data = load_dataset(\"tweet_eval\", \"emotion\")\n",
        "train_data = pd.DataFrame(data['train'])\n",
        "train_data.to_csv(\"tweet_eval_emotion.csv\", index=False)\n",
        "\n",
        "# Spark DataFrame'e Yükleme\n",
        "df = spark.read.csv(\"tweet_eval_emotion.csv\", header=True, inferSchema=True)\n",
        "df = df.select(col(\"text\").alias(\"tweet\"), col(\"label\").cast(\"integer\"))  # Sütunları yeniden adlandırma\n",
        "\n",
        "# Veri Ön İşleme\n",
        "df = df.withColumn(\"tweet\", lower(col(\"tweet\")))  # Küçük harfe çevirme\n",
        "df = df.withColumn(\"tweet\", regexp_replace(col(\"tweet\"), \"[^a-zA-Z\\\\s]\", \"\"))  # Özel karakterleri temizleme\n",
        "\n",
        "# Dağıtılmış Fonksiyon: Tweet Uzunluğunu Hesaplama\n",
        "def tweet_length(tweet):\n",
        "    return len(tweet.split())\n",
        "\n",
        "# UDF Tanımlama\n",
        "tweet_length_udf = udf(tweet_length, IntegerType())\n",
        "\n",
        "# UDF ile Yeni Sütun Ekleme\n",
        "df = df.withColumn(\"tweet_length\", tweet_length_udf(col(\"tweet\")))\n",
        "\n",
        "# Spark Shuffle Partition ayarı (Hız için)\n",
        "spark.conf.set(\"spark.sql.shuffle.partitions\", \"4\")\n",
        "\n",
        "# Tokenization, Stopwords, TF-IDF ve Özellik Ölçeklendirme\n",
        "tokenizer = Tokenizer(inputCol=\"tweet\", outputCol=\"words\")\n",
        "stopwords_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
        "hashing_tf = HashingTF(inputCol=\"filtered_words\", outputCol=\"rawFeatures\", numFeatures=20000)\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5)\n",
        "\n",
        "# Özellikleri Ölçeklendirme\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=False)\n",
        "\n",
        "# Logistic Regression Model\n",
        "lr = LogisticRegression(featuresCol=\"scaled_features\", labelCol=\"label\")\n",
        "\n",
        "# Pipeline\n",
        "pipeline = Pipeline(stages=[tokenizer, stopwords_remover, hashing_tf, idf, scaler, lr])\n",
        "\n",
        "# Modeli Eğitme\n",
        "model = pipeline.fit(df)\n",
        "predictions = model.transform(df)\n",
        "\n",
        "# Performans Değerlendirme\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Logistic Regression Doğruluğu: {accuracy:.2f}\")\n",
        "\n",
        "# En İyi Tahminleri Gösterme\n",
        "predictions.select(\"tweet\", \"label\", \"prediction\").show(5)\n",
        "\n",
        "# Dağıtılmış Tweet Uzunluğu Görüntüleme\n",
        "df.select(\"tweet\", \"tweet_length\").show(10)\n",
        "\n",
        "# Spark oturumunu kapatma\n",
        "spark.stop()\n"
      ]
    }
  ]
}